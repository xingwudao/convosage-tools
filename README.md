## recognizer

### 1.bubble_detector
- 采取先把气泡分割出来的原因：真实聊天场景中存在大量非聊天文本干扰，来自系统，状态栏，背景，带有文字的图片/链接卡片/聊天背景等等。CV算法以及坐标定位算法无法准确识别出气泡，因此决定先用YOLO模型分割出气泡，再识别。
- 分割模型：YOLOv8n
- 训练数据集：需要标注的是对方发送气泡，我方发送气泡，以及除这两者之外容易造成干扰的其他消息如图片，链接卡片等。YOLO数据集格式，需要标注框的左上角坐标，右下角坐标，以及类别。
- 合成数据集工具：
tools\data_tools\dark_green_label_producer.py
tools\data_tools\light_green_label_producer.py
考虑到深色模式与浅色模式差别较大，为了更准确地识别以及更高效的训练，因此生成两种数据集各1000张图片，分别训练两个模型。
手动标注需要花费大量时间精力，因此采用聊天记录截图的方式。再生成图片的同时，生成标注文件。
- 数据多样化策略：聊天背景，头像，图片，链接卡片从预先准备集合中随机选取添加，添加概率在一定范围内随机。状态栏绘制，出现概率0.5。文本从集合中随机挑选，有长有短，有中文有英文。
- 训练结果：两种模型召回率均达到0.995，

- 弃用方案：直接使用CV算法，识别出气泡，再识别。但CV算法识别效果不稳定，容易被干扰。

### 2.OCR
- 检测识别模型：PP-OCRv5_mobile_det，PP-OCRv5_mobile_rec
- 模型选取：PaddleOCR识别中文优势明显，且模型大小适中，识别速度较快，因此选择PaddleOCR。缺点在于，更新频率较高，参数配置需要注意是否符合版本，尤其不要依赖AI。
- 检测识别逻辑：
先整图检测，得到文本块，再根据文本块中心位置，位于气泡内的，加入到识别队列，进行识别。
文本块坐标**遍历**除了others类别外所有气泡框范围
- **识别结果**：短文本平均置信度>0.98,长文本平均置信度>0.95

- **PPOCR使用注意点**：不同版本模型参数名称、设置格式不同;
不同版本不同参数，ocr返回结果**数据类型**不同，解析时需要注意。
> 💡 **PaddleOCR 版本返回结果格式说明**
>
> - **2.6 及以上版本**：支持列表和字典两种格式，参数 `return_result=True` 控制列表格式，`use_mp=True` 多进程模式可触发字典格式。
> - **3.0 及以上版本**：主流采用字典格式，包含 `'boxes'`（检测框）、`'texts'`（识别文本）、`'scores'`（置信度）等键，结构更清晰。
>
> 💡 **PaddleOCR 早期与新版返回格式说明**
>
> - **2.5 及以前版本**  
>   返回结果为纯列表，每个元素结构如下：  
>   `[[[x1,y1,x2,y2,x3,y3,x4,y4], ("文本", 0.99)], ...]`  
>   - `[x1,y1,x2,y2,x3,y3,x4,y4]`：文本框四个顶点坐标  
>   - `"文本"`：识别出的内容  
>   - `0.99`：置信度  
>   结构简单易解析，但不便于区分检测、识别、方向分类等多阶段结果。
>
> - **2.6 及以上版本**  
>   引入字典格式，返回结果为列表套字典（单张图片时长度为 1）：  
>   `[{ 'det_boxes': [...], 'rec_texts': [...], 'rec_scores': [...] }]`  
>   - `'det_boxes'`：文本检测框列表  
>   - `'rec_texts'`：识别文本列表  
>   - `'rec_scores'`：识别置信度列表  
>   - 若启用方向分类，还包含 `'cls_labels'`（方向标签）和 `'cls_scores'`（方向置信度）  
>   结构更清晰，便于多阶段结果解析。
>

>
> **不同版本返回格式示例：**
>
> | 版本         | 返回格式示例                                                         |
> |--------------|---------------------------------------------------------------------|
> | 2.5 及以下   | `[[[x1,y1,x2,y2,x3,y3,x4,y4], ("文本", 0.99)], ...]`                |
> | 2.6 - 2.9    | `{"det": [...], "rec": [("文本", 0.99), ...]}`                      |
> | 3.0+         | `{"boxes": [...], "texts": ["文本1", "文本2"], "scores": [0.99, ...]}` |
>
> **代码适配建议：**
>
> ```python
> ocr_results = self.ocr_engine.ocr(image)
> if isinstance(ocr_results, dict):
>     boxes = ocr_results["boxes"]
>     texts = ocr_results["texts"]
>     scores = ocr_results["scores"]
> else:
>     texts = [line[1][0] for line in ocr_results]
>     scores = [line[1][1] for line in ocr_results]
> ```
>
> > ⚠️ 建议升级 PaddleOCR 至 3.0+，并参考官方文档解析最新输出结构。

- 弃用方案：PPOCR 核心基于卷积神经网络，其识别效果受输入图像尺寸影响。当分割后的气泡图像尺寸差异较大时，直接送入模型可能导致不稳定，原因如下：
1.模型输入要求：PP-OCR 通常期望输入高度为 32 像素的图像，若气泡文本区域高度不足，需通过插值放大，但过度放大会导致文字模糊。
2.预处理挑战：不同大小的气泡可能需要不同的预处理策略（如对比度增强、去噪），单一参数难以覆盖所有场景。
3.特征提取限制：过小的文本区域可能无法提供足够的特征供模型识别。